<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Advanced Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;50 of 17,330 results
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  
    

    <div class="columns">
      <div class="column is-two-thirds-tablet">
        <p style="margin-bottom: .5em">Query: <a href="/search/advanced?terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first">order: -announced_date_first; size: 50; date_range: from 2024-06-01 to 2024-12-01; classification: Computer Science (cs); terms: AND cross_list_category=Artificial Intelligence</a></p>
        <div class="buttons">
          <a class="button is-link" href="/search/advanced?terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first">Refine query</a><a class="button" href="/search/advanced">New search</a>
        </div>
      </div>
      <div class="column is-one-third-tablet is-hidden-mobile">
        <p class="has-text-right" style="margin-top: 1em">
          
          <a href="/search/?order=-announced_date_first&amp;size=50">Simple Search</a>
          
        </p>
      </div>
    </div>

    
        
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/advanced">
      <div style="display: none;">
        
          
            <input id="advanced" name="advanced" type="hidden" value="">
          
        
          
            <ul id="terms"><li><label for="terms-0">Terms-0</label> <table id="terms-0"><tr><th><label for="terms-0-term">Search term...</label></th><td><input id="terms-0-term" name="terms-0-term" type="text" value="Artificial Intelligence"></td></tr><tr><th><label for="terms-0-operator">Operator</label></th><td><select id="terms-0-operator" name="terms-0-operator"><option selected value="AND">AND</option><option value="OR">OR</option><option value="NOT">NOT</option></select></td></tr><tr><th><label for="terms-0-field">Field</label></th><td><select id="terms-0-field" name="terms-0-field"><option value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option selected value="cross_list_category">Cross-list category</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="author_id">arXiv author ID</option><option value="all">All fields</option></select></td></tr></table></li></ul>
          
        
          
            <table id="classification"><tr><th><label for="classification-computer_science">Computer Science (cs)</label></th><td><input checked id="classification-computer_science" name="classification-computer_science" type="checkbox" value="y"></td></tr><tr><th><label for="classification-economics">Economics (econ)</label></th><td><input id="classification-economics" name="classification-economics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-eess">Electrical Engineering and Systems Science (eess)</label></th><td><input id="classification-eess" name="classification-eess" type="checkbox" value="y"></td></tr><tr><th><label for="classification-mathematics">Mathematics (math)</label></th><td><input id="classification-mathematics" name="classification-mathematics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-physics">Physics</label></th><td><input id="classification-physics" name="classification-physics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-physics_archives">Physics Archives</label></th><td><select id="classification-physics_archives" name="classification-physics_archives"><option selected value="all">all</option><option value="astro-ph">astro-ph</option><option value="cond-mat">cond-mat</option><option value="gr-qc">gr-qc</option><option value="hep-ex">hep-ex</option><option value="hep-lat">hep-lat</option><option value="hep-ph">hep-ph</option><option value="hep-th">hep-th</option><option value="math-ph">math-ph</option><option value="nlin">nlin</option><option value="nucl-ex">nucl-ex</option><option value="nucl-th">nucl-th</option><option value="physics">physics</option><option value="quant-ph">quant-ph</option></select></td></tr><tr><th><label for="classification-q_biology">Quantitative Biology (q-bio)</label></th><td><input id="classification-q_biology" name="classification-q_biology" type="checkbox" value="y"></td></tr><tr><th><label for="classification-q_finance">Quantitative Finance (q-fin)</label></th><td><input id="classification-q_finance" name="classification-q_finance" type="checkbox" value="y"></td></tr><tr><th><label for="classification-statistics">Statistics (stat)</label></th><td><input id="classification-statistics" name="classification-statistics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-include_cross_list">Include cross-list</label></th><td><ul id="classification-include_cross_list"><li><input id="classification-include_cross_list-0" name="classification-include_cross_list" type="radio" value="include"> <label for="classification-include_cross_list-0">Include cross-listed papers</label></li><li><input checked id="classification-include_cross_list-1" name="classification-include_cross_list" type="radio" value="exclude"> <label for="classification-include_cross_list-1">Exclude cross-listed papers</label></li></ul></td></tr></table>
          
        
          
            <table id="date"><tr><th><label for="date-filter_by">Filter by</label></th><td><ul id="date-filter_by"><li><input id="date-filter_by-0" name="date-filter_by" type="radio" value="all_dates"> <label for="date-filter_by-0">All dates</label></li><li><input id="date-filter_by-1" name="date-filter_by" type="radio" value="past_12"> <label for="date-filter_by-1">Past 12 months</label></li><li><input id="date-filter_by-2" name="date-filter_by" type="radio" value="specific_year"> <label for="date-filter_by-2">Specific year</label></li><li><input checked id="date-filter_by-3" name="date-filter_by" type="radio" value="date_range"> <label for="date-filter_by-3">Date range</label></li></ul></td></tr><tr><th><label for="date-year">Year</label></th><td><input id="date-year" name="date-year" type="text" value=""></td></tr><tr><th><label for="date-from_date">From</label></th><td><input id="date-from_date" name="date-from_date" type="text" value="2024-06-01"></td></tr><tr><th><label for="date-to_date">to</label></th><td><input id="date-to_date" name="date-to_date" type="text" value="2024-12-01"></td></tr><tr><th><label for="date-date_type">Apply to</label></th><td><ul id="date-date_type"><li><input checked id="date-date_type-0" name="date-date_type" type="radio" value="submitted_date"> <label for="date-date_type-0">Submission date (most recent)</label></li><li><input id="date-date_type-1" name="date-date_type" type="radio" value="submitted_date_first"> <label for="date-date_type-1">Submission date (original)</label></li><li><input id="date-date_type-2" name="date-date_type" type="radio" value="announced_date_first"> <label for="date-date_type-2">Announcement date</label></li></ul></td></tr></table>
          
        
          
        
          
        
          
            <input id="include_older_versions" name="include_older_versions" type="checkbox" value="y">
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
        


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
                                     
          
          <li>
            <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=50"
              class="pagination-link "
              aria-label="Page 2"
              aria-current="page">2
            </a>
          </li>
          
          <li>
            <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=100"
              class="pagination-link "
              aria-label="Page 3"
              aria-current="page">3
            </a>
          </li>
          
          <li>
            <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=150"
              class="pagination-link "
              aria-label="Page 4"
              aria-current="page">4
            </a>
          </li>
          
          <li>
            <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=200"
              class="pagination-link "
              aria-label="Page 5"
              aria-current="page">5
            </a>
          </li>
          
          <li><span class="pagination-ellipsis">&hellip;</span></li>
        
      
    </ul>
  </nav>
  



<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.04326">arXiv:2412.04326</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.04326">pdf</a>, <a href="https://arxiv.org/format/2412.04326">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Understanding Student Sentiment on Mental Health Support in Colleges Using Large Language Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sood%2C+P">Palak Sood</a>, 
      
      <a href="/search/?searchtype=author&amp;query=He%2C+C">Chengyang He</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gupta%2C+D">Divyanshu Gupta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ning%2C+Y">Yue Ning</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+P">Ping Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.04326v1-abstract-short" style="display: inline;">
        Mental health support in colleges is vital in educating students by offering counseling services and organizing supportive events. However, evaluating its effectiveness faces challenges like data collection difficulties and lack of standardized metrics, limiting research scope. Student feedback is crucial for evaluation but often relies on qualitative analysis without systematic investigation usin&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.04326v1-abstract-full').style.display = 'inline'; document.getElementById('2412.04326v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.04326v1-abstract-full" style="display: none;">
        Mental health support in colleges is vital in educating students by offering counseling services and organizing supportive events. However, evaluating its effectiveness faces challenges like data collection difficulties and lack of standardized metrics, limiting research scope. Student feedback is crucial for evaluation but often relies on qualitative analysis without systematic investigation using advanced machine learning methods. This paper uses public Student Voice Survey data to analyze student sentiments on mental health support with large language models (LLMs). We created a sentiment analysis dataset, SMILE-College, with human-machine collaboration. The investigation of both traditional machine learning methods and state-of-the-art LLMs showed the best performance of GPT-3.5 and BERT on this new dataset. The analysis highlights challenges in accurately predicting response sentiments and offers practical insights on how LLMs can enhance mental health-related research and improve college mental health services. This data-driven approach will facilitate efficient and informed mental health support evaluation, management, and decision-making.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.04326v1-abstract-full').style.display = 'none'; document.getElementById('2412.04326v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by &#39;2024 IEEE International Conference on Big Data (IEEE BigData 2024)&#39;. The paper has 8 pages, 2 figures, 4 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03594">arXiv:2412.03594</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03594">pdf</a>, <a href="https://arxiv.org/format/2412.03594">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix Sharing and Throughput-oriented Token Batching
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zheng%2C+Z">Zhen Zheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ji%2C+X">Xin Ji</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fang%2C+T">Taosong Fang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+F">Fanghao Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+C">Chuanjie Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+G">Gang Peng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03594v1-abstract-short" style="display: inline;">
        Many LLM tasks are performed in large batches or even offline, and the performance indictor for which is throughput. These tasks usually show the characteristic of prefix sharing, where different prompt input can partially show the common prefix. However, the existing LLM inference engines tend to optimize the streaming requests and show limitations of supporting the large batched tasks with the p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03594v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03594v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03594v1-abstract-full" style="display: none;">
        Many LLM tasks are performed in large batches or even offline, and the performance indictor for which is throughput. These tasks usually show the characteristic of prefix sharing, where different prompt input can partially show the common prefix. However, the existing LLM inference engines tend to optimize the streaming requests and show limitations of supporting the large batched tasks with the prefix sharing characteristic. The existing solutions use the LRU-based cache to reuse the KV context of common prefix. The KV context that is about to be reused may prematurely be evicted with the implicit cache management. Even if not evicted, the lifetime of the shared KV context is extended since requests sharing the same context are not scheduled together, resulting in larger memory usage. These streaming oriented systems schedule the requests in the first-come-first-serve or similar order. As a result, the requests with larger ratio of decoding steps may be scheduled too late to be able to mix with the prefill chunks to increase the hardware utilization. Besides, the token and request number based batching can limit the size of token-batch, which keeps the GPU from saturating for the iterations dominated by decoding tokens. We propose BatchLLM to address the above problems. BatchLLM explicitly identifies the common prefixes globally. The requests sharing the same prefix will be scheduled together to reuse the KV context the best, which also shrinks the lifetime of common KV memory. BatchLLM reorders the requests and schedules the requests with larger ratio of decoding first to better mix the decoding tokens with the latter prefill chunks and applies memory-centric token batching to enlarge the token-batch sizes, which helps to increase the GPU utilization. Extensive evaluation shows that BatchLLM outperforms vLLM by 1.1x to 2x on a set of microbenchmarks and two typical industry workloads.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03594v1-abstract-full').style.display = 'none'; document.getElementById('2412.03594v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03593">arXiv:2412.03593</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03593">pdf</a>, <a href="https://arxiv.org/format/2412.03593">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CovidLLM: A Robust Large Language Model with Missing Value Adaptation and Multi-Objective Learning Strategy for Predicting Disease Severity and Clinical Outcomes in COVID-19 Patients
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+S">Shengjun Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+S">Siyu Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Y">Yang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lei%2C+Q">Qing Lei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hou%2C+H">Hongyan Hou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+H">Hewei Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+S">Shujuan Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+F">Feng Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+R">Rongshang Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+X">Xionglin Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tao%2C+S">Shengce Tao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+J">Jiaxin Cai</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03593v1-abstract-short" style="display: inline;">
        Coronavirus Disease 2019 (COVID-19), which emerged in 2019, has caused millions of deaths worldwide. Although effective vaccines have been developed to mitigate severe symptoms, certain populations, particularly the elderly and those with comorbidities, remain at high risk for severe outcomes and increased mortality. Consequently, early identification of the severity and clinical outcomes of the d&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03593v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03593v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03593v1-abstract-full" style="display: none;">
        Coronavirus Disease 2019 (COVID-19), which emerged in 2019, has caused millions of deaths worldwide. Although effective vaccines have been developed to mitigate severe symptoms, certain populations, particularly the elderly and those with comorbidities, remain at high risk for severe outcomes and increased mortality. Consequently, early identification of the severity and clinical outcomes of the disease in these patients is vital to prevent adverse prognoses. Although traditional machine learning and deep learning models have been widely employed in this area, the potential of large language models (LLMs) remains largely unexplored. Our research focuses primarily on constructing specialized prompts and adopting multi-objective learning strategies. We started by selecting serological indicators that significantly correlate with clinical outcomes and disease severity to serve as input data for the model. Blood test samples often contain numerous missing values, and traditional models generally rely on imputation to handle these gaps in the data. In contrast, LLMs offer the advantage of robust semantic understanding. By setting prompts, we can explicitly inform the model when a feature&#39;s value is missing, without the need for imputation. For the multi-objective learning strategy, the model is designed to first predict disease severity and then predict clinical outcomes. Given that LLMs utilize both the input text and the generated tokens as input for generating the next token, the predicted severity is used as a basis for generating the clinical outcome. During the fine-tuning of the LLM, the two objectives influence and improve each other. Our experiments were implemented based on the ChatGLM model. The results demonstrate the effectiveness of LLMs in this task, suggesting promising potential for further development.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03593v1-abstract-full').style.display = 'none'; document.getElementById('2412.03593v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03592">arXiv:2412.03592</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03592">pdf</a>, <a href="https://arxiv.org/format/2412.03592">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Using Images to Find Context-Independent Word Representations in Vector Space
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+H">Harsh Kumar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03592v1-abstract-short" style="display: inline;">
        Many methods have been proposed to find vector representation for words, but most rely on capturing context from the text to find semantic relationships between these vectors. We propose a novel method of using dictionary meanings and image depictions to find word vectors independent of any context. We use auto-encoder on the word images to find meaningful representations and use them to calculate&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03592v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03592v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03592v1-abstract-full" style="display: none;">
        Many methods have been proposed to find vector representation for words, but most rely on capturing context from the text to find semantic relationships between these vectors. We propose a novel method of using dictionary meanings and image depictions to find word vectors independent of any context. We use auto-encoder on the word images to find meaningful representations and use them to calculate the word vectors. We finally evaluate our method on word similarity, concept categorization and outlier detection tasks. Our method performs comparably to context-based methods while taking much less training time.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03592v1-abstract-full').style.display = 'none'; document.getElementById('2412.03592v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03590">arXiv:2412.03590</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03590">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.17577/IJERTV13IS100138">10.17577/IJERTV13IS100138 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Enhancing Document AI Data Generation Through Graph-Based Synthetic Layouts
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Agarwal%2C+A">Amit Agarwal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Patel%2C+H">Hitesh Patel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pattnayak%2C+P">Priyaranjan Pattnayak</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Panda%2C+S">Srikant Panda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+B">Bhargava Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+T">Tejaswini Kumar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03590v1-abstract-short" style="display: inline;">
        The development of robust Document AI models has been constrained by limited access to high-quality, labeled datasets, primarily due to data privacy concerns, scarcity, and the high cost of manual annotation. Traditional methods of synthetic data generation, such as text and image augmentation, have proven effective for increasing data diversity but often fail to capture the complex layout structu&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03590v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03590v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03590v1-abstract-full" style="display: none;">
        The development of robust Document AI models has been constrained by limited access to high-quality, labeled datasets, primarily due to data privacy concerns, scarcity, and the high cost of manual annotation. Traditional methods of synthetic data generation, such as text and image augmentation, have proven effective for increasing data diversity but often fail to capture the complex layout structures present in real world documents. This paper proposes a novel approach to synthetic document layout generation using Graph Neural Networks (GNNs). By representing document elements (e.g., text blocks, images, tables) as nodes in a graph and their spatial relationships as edges, GNNs are trained to generate realistic and diverse document layouts. This method leverages graph-based learning to ensure structural coherence and semantic consistency, addressing the limitations of traditional augmentation techniques. The proposed framework is evaluated on tasks such as document classification, named entity recognition (NER), and information extraction, demonstrating significant performance improvements. Furthermore, we address the computational challenges of GNN based synthetic data generation and propose solutions to mitigate domain adaptation issues between synthetic and real-world datasets. Our experimental results show that graph-augmented document layouts outperform existing augmentation techniques, offering a scalable and flexible solution for training Document AI models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03590v1-abstract-full').style.display = 'none'; document.getElementById('2412.03590v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Published in IJERT, Volume 13, Issue 10 (October 2024)</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.6; I.2.7; I.5.4; H.3.3; H.2.8; G.2.2
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        IJERT, Volume 13, Issue 10, October 2024
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03587">arXiv:2412.03587</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03587">pdf</a>, <a href="https://arxiv.org/format/2412.03587">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Not All Adapters Matter: Selective Adapter Freezing for Memory-Efficient Fine-Tuning of Language Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Son%2C+H">Hyegang Son</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Son%2C+Y">Yonglak Son</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+C">Changhoon Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+Y+G">Young Geun Kim</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03587v1-abstract-short" style="display: inline;">
        Transformer-based large-scale pre-trained models achieve great success, and fine-tuning, which tunes a pre-trained model on a task-specific dataset, is the standard practice to utilize these models for downstream tasks. Recent work has developed adapter-tuning, but these approaches either still require a relatively high resource usage. Through our investigation, we show that each adapter in adapte&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03587v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03587v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03587v1-abstract-full" style="display: none;">
        Transformer-based large-scale pre-trained models achieve great success, and fine-tuning, which tunes a pre-trained model on a task-specific dataset, is the standard practice to utilize these models for downstream tasks. Recent work has developed adapter-tuning, but these approaches either still require a relatively high resource usage. Through our investigation, we show that each adapter in adapter-tuning does not have the same impact on task performance and resource usage. Based on our findings, we propose SAFE, which gradually freezes less-important adapters that do not contribute to adaptation during the early training steps. In our experiments, SAFE reduces memory usage, computation amount, and training time by 42.85\%, 34.59\%, and 11.82\%, respectively, while achieving comparable or better performance compared to the baseline. We also demonstrate that SAFE induces regularization effect, thereby smoothing the loss landscape.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03587v1-abstract-full').style.display = 'none'; document.getElementById('2412.03587v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03581">arXiv:2412.03581</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03581">pdf</a>, <a href="https://arxiv.org/format/2412.03581">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Survey on E-Commerce Learning to Rank
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kabir%2C+M+A">Md. Ahsanul Kabir</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hasan%2C+M+A">Mohammad Al Hasan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mandal%2C+A">Aritra Mandal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tunkelang%2C+D">Daniel Tunkelang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Z">Zhe Wu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03581v1-abstract-short" style="display: inline;">
        In e-commerce, ranking the search results based on users&#39; preference is the most important task. Commercial e-commerce platforms, such as, Amazon, Alibaba, eBay, Walmart, etc. perform extensive and relentless research to perfect their search result ranking algorithms because the quality of ranking drives a user&#39;s decision to purchase or not to purchase an item, directly affecting the profitability&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03581v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03581v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03581v1-abstract-full" style="display: none;">
        In e-commerce, ranking the search results based on users&#39; preference is the most important task. Commercial e-commerce platforms, such as, Amazon, Alibaba, eBay, Walmart, etc. perform extensive and relentless research to perfect their search result ranking algorithms because the quality of ranking drives a user&#39;s decision to purchase or not to purchase an item, directly affecting the profitability of the e-commerce platform. In such a commercial platforms, for optimizing search result ranking numerous features are considered, which emerge from relevance, personalization, seller&#39;s reputation and paid promotion. To maintain their competitive advantage in the market, the platforms do no publish their core ranking algorithms, so it is difficult to know which of the algorithms or which of the features is the most effective for finding the most optimal search result ranking in e-commerce. No extensive surveys of ranking to rank in the e-commerce domain is also not yet published. In this work, we survey the existing e-commerce learning to rank algorithms. Besides, we also compare these algorithms based on query relevance criterion on a large real-life e-commerce dataset and provide a quantitative analysis. To the best of our knowledge this is the first such survey which include an experimental comparison among various learning to rank algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03581v1-abstract-full').style.display = 'none'; document.getElementById('2412.03581v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03580">arXiv:2412.03580</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03580">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Reinforced Symbolic Learning with Logical Constraints for Predicting Turbine Blade Fatigue Life
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+P">Pei Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Choi%2C+J">Joo-Ho Choi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+D">Dingyang Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+S">Shuyou Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">Yiming Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03580v1-abstract-short" style="display: inline;">
        Accurate prediction of turbine blade fatigue life is essential for ensuring the safety and reliability of aircraft engines. A significant challenge in this domain is uncovering the intrinsic relationship between mechanical properties and fatigue life. This paper introduces Reinforced Symbolic Learning (RSL), a method that derives predictive formulas linking these properties to fatigue life. RSL in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03580v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03580v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03580v1-abstract-full" style="display: none;">
        Accurate prediction of turbine blade fatigue life is essential for ensuring the safety and reliability of aircraft engines. A significant challenge in this domain is uncovering the intrinsic relationship between mechanical properties and fatigue life. This paper introduces Reinforced Symbolic Learning (RSL), a method that derives predictive formulas linking these properties to fatigue life. RSL incorporates logical constraints during symbolic optimization, ensuring that the generated formulas are both physically meaningful and interpretable. The optimization process is further enhanced using deep reinforcement learning, which efficiently guides the symbolic regression towards more accurate models. The proposed RSL method was evaluated on two turbine blade materials, GH4169 and TC4, to identify optimal fatigue life prediction models. When compared with six empirical formulas and five machine learning algorithms, RSL not only produces more interpretable formulas but also achieves superior or comparable predictive accuracy. Additionally, finite element simulations were conducted to assess mechanical properties at critical points on the blade, which were then used to predict fatigue life under various operating conditions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03580v1-abstract-full').style.display = 'none'; document.getElementById('2412.03580v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">full-lenth article with 24 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03579">arXiv:2412.03579</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03579">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards a Practical Ethics of Generative AI in Creative Production Processes
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hofman%2C+G">Geert Hofman</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03579v1-abstract-short" style="display: inline;">
        The increasing integration of artificial intelligence into various domains, including design and creative processes, raises significant ethical questions. While AI ethics is often examined from the perspective of technology developers, less attention has been paid to the practical ethical considerations faced by technology users, particularly in design contexts. This paper introduces a framework f&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03579v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03579v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03579v1-abstract-full" style="display: none;">
        The increasing integration of artificial intelligence into various domains, including design and creative processes, raises significant ethical questions. While AI ethics is often examined from the perspective of technology developers, less attention has been paid to the practical ethical considerations faced by technology users, particularly in design contexts. This paper introduces a framework for addressing ethical challenges in creative production processes, such as the Double Diamond design model. Drawing on six major ethical theories - virtue ethics, deontology, utilitarianism, contract theory, care ethics, and existentialism - we develop a &#34;compass&#34; to navigate and reflect on the ethical dimensions of AI in design. The framework highlights the importance of responsibility, anticipation, and reflection across both the AI lifecycle and each stage of the creative process. We argue that by adopting a playful and exploratory approach to AI, while remaining anchored in core ethical principles, designers can responsibly harness the potential of AI technologies without overburdening or compromising their creative processes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03579v1-abstract-full').style.display = 'none'; document.getElementById('2412.03579v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03578">arXiv:2412.03578</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03578">pdf</a>, <a href="https://arxiv.org/format/2412.03578">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PerfCodeGen: Improving Performance of LLM Generated Code with Execution Feedback
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+Y">Yun Peng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gotmare%2C+A+D">Akhilesh Deepak Gotmare</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lyu%2C+M">Michael Lyu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiong%2C+C">Caiming Xiong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Savarese%2C+S">Silvio Savarese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sahoo%2C+D">Doyen Sahoo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03578v1-abstract-short" style="display: inline;">
        Large Language Models (LLMs) are widely adopted for assisting in software development tasks, yet their performance evaluations have narrowly focused on the functional correctness of generated code. Human programmers, however, require LLM-generated code to be not only correct but also optimally efficient. We propose PerfCodeGen, a training-free framework that enhances the performance of LLM-generat&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03578v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03578v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03578v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) are widely adopted for assisting in software development tasks, yet their performance evaluations have narrowly focused on the functional correctness of generated code. Human programmers, however, require LLM-generated code to be not only correct but also optimally efficient. We propose PerfCodeGen, a training-free framework that enhances the performance of LLM-generated code by incorporating feedback based on runtime during test case execution into the self-refinement iterations. With PerfCodeGen, we achieve speedups for a significantly higher proportion of problems compared to using the base LLM with sophisticated prompting techniques. Applied to open language models like Phi-3-mini, PerfCodeGen achieves runtime efficiency comparable to prompting powerful closed models like GPT-4. We achieve state-of-the-art runtime efficiency on benchmarks such as HumanEval, MBPP, and APPS, frequently surpassing the ground truth reference solutions with PerfCodeGen using GPT-3.5 and GPT-4. Additionally, we demonstrate the effectiveness of our approach in enhancing code quality across a range of open LLMs of varying sizes including Phi-3-mini, Llama 3 8B, Mixtral 8x7B, Command R, and Llama 3 70B.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03578v1-abstract-full').style.display = 'none'; document.getElementById('2412.03578v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03577">arXiv:2412.03577</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03577">pdf</a>, <a href="https://arxiv.org/format/2412.03577">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        OKG: On-the-Fly Keyword Generation in Sponsored Search Advertising
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">Zhao Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gangopadhyay%2C+B">Briti Gangopadhyay</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+M">Mengjie Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Takamatsu%2C+S">Shingo Takamatsu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03577v1-abstract-short" style="display: inline;">
        Current keyword decision-making in sponsored search advertising relies on large, static datasets, limiting the ability to automatically set up keywords and adapt to real-time KPI metrics and product updates that are essential for effective advertising. In this paper, we propose On-the-fly Keyword Generation (OKG), an LLM agent-based method that dynamically monitors KPI changes and adapts keyword g&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03577v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03577v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03577v1-abstract-full" style="display: none;">
        Current keyword decision-making in sponsored search advertising relies on large, static datasets, limiting the ability to automatically set up keywords and adapt to real-time KPI metrics and product updates that are essential for effective advertising. In this paper, we propose On-the-fly Keyword Generation (OKG), an LLM agent-based method that dynamically monitors KPI changes and adapts keyword generation in real time, aligning with strategies recommended by advertising platforms. Additionally, we introduce the first publicly accessible dataset containing real keyword data along with its KPIs across diverse domains, providing a valuable resource for future research. Experimental results show that OKG significantly improves keyword adaptability and responsiveness compared to traditional methods. The code for OKG and the dataset are available at https://github.com/sony/okg.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03577v1-abstract-full').style.display = 'none'; document.getElementById('2412.03577v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03576">arXiv:2412.03576</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03576">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Ethical Challenges and Evolving Strategies in the Integration of Artificial Intelligence into Clinical Practice
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Weiner%2C+E+B">Ellison B. Weiner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dankwa-Mullan%2C+I">Irene Dankwa-Mullan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nelson%2C+W+A">William A. Nelson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hassanpour%2C+S">Saeed Hassanpour</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03576v1-abstract-short" style="display: inline;">
        Artificial intelligence (AI) has rapidly transformed various sectors, including healthcare, where it holds the potential to revolutionize clinical practice and improve patient outcomes. However, its integration into medical settings brings significant ethical challenges that need careful consideration. This paper examines the current state of AI in healthcare, focusing on five critical ethical con&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03576v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03576v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03576v1-abstract-full" style="display: none;">
        Artificial intelligence (AI) has rapidly transformed various sectors, including healthcare, where it holds the potential to revolutionize clinical practice and improve patient outcomes. However, its integration into medical settings brings significant ethical challenges that need careful consideration. This paper examines the current state of AI in healthcare, focusing on five critical ethical concerns: justice and fairness, transparency, patient consent and confidentiality, accountability, and patient-centered and equitable care. These concerns are particularly pressing as AI systems can perpetuate or even exacerbate existing biases, often resulting from non-representative datasets and opaque model development processes. The paper explores how bias, lack of transparency, and challenges in maintaining patient trust can undermine the effectiveness and fairness of AI applications in healthcare. In addition, we review existing frameworks for the regulation and deployment of AI, identifying gaps that limit the widespread adoption of these systems in a just and equitable manner. Our analysis provides recommendations to address these ethical challenges, emphasizing the need for fairness in algorithm design, transparency in model decision-making, and patient-centered approaches to consent and data privacy. By highlighting the importance of continuous ethical scrutiny and collaboration between AI developers, clinicians, and ethicists, we outline pathways for achieving more responsible and inclusive AI implementation in healthcare. These strategies, if adopted, could enhance both the clinical value of AI and the trustworthiness of AI systems among patients and healthcare professionals, ensuring that these technologies serve all populations equitably.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03576v1-abstract-full').style.display = 'none'; document.getElementById('2412.03576v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03575">arXiv:2412.03575</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03575">pdf</a>, <a href="https://arxiv.org/format/2412.03575">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3687123.3698298">10.1145/3687123.3698298 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Leveraging Large Language Models for Generating Labeled Mineral Site Record Linkage Data
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pyo%2C+J">Jiyoon Pyo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chiang%2C+Y">Yao-Yi Chiang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03575v1-abstract-short" style="display: inline;">
        Record linkage integrates diverse data sources by identifying records that refer to the same entity. In the context of mineral site records, accurate record linkage is crucial for identifying and mapping mineral deposits. Properly linking records that refer to the same mineral deposit helps define the spatial coverage of mineral areas, benefiting resource identification and site data archiving. Mi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03575v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03575v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03575v1-abstract-full" style="display: none;">
        Record linkage integrates diverse data sources by identifying records that refer to the same entity. In the context of mineral site records, accurate record linkage is crucial for identifying and mapping mineral deposits. Properly linking records that refer to the same mineral deposit helps define the spatial coverage of mineral areas, benefiting resource identification and site data archiving. Mineral site record linkage falls under the spatial record linkage category since the records contain information about the physical locations and non-spatial attributes in a tabular format. The task is particularly challenging due to the heterogeneity and vast scale of the data. While prior research employs pre-trained discriminative language models (PLMs) on spatial entity linkage, they often require substantial amounts of curated ground-truth data for fine-tuning. Gathering and creating ground truth data is both time-consuming and costly. Therefore, such approaches are not always feasible in real-world scenarios where gold-standard data are unavailable. Although large generative language models (LLMs) have shown promising results in various natural language processing tasks, including record linkage, their high inference time and resource demand present challenges. We propose a method that leverages an LLM to generate training data and fine-tune a PLM to address the training data gap while preserving the efficiency of PLMs. Our approach achieves over 45\% improvement in F1 score for record linkage compared to traditional PLM-based methods using ground truth data while reducing the inference time by nearly 18 times compared to relying on LLMs. Additionally, we offer an automated pipeline that eliminates the need for human intervention, highlighting this approach&#39;s potential to overcome record linkage challenges.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03575v1-abstract-full').style.display = 'none'; document.getElementById('2412.03575v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11 pages, 10 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03574">arXiv:2412.03574</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03574">pdf</a>, <a href="https://arxiv.org/format/2412.03574">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Back-filling Missing Data When Predicting Domestic Electricity Consumption From Smart Meter Data
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+X">Xianjuan Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+S">Shuxiang Cai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Smeaton%2C+A+F">Alan F. Smeaton</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03574v1-abstract-short" style="display: inline;">
        This study uses data from domestic electricity smart meters to estimate annual electricity bills for a whole year. We develop a method for back-filling data smart meter for up to six missing months for users who have less than one year of smart meter data, ensuring reliable estimates of annual consumption. We identify five distinct electricity consumption user profiles for homes based on day, nigh&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03574v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03574v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03574v1-abstract-full" style="display: none;">
        This study uses data from domestic electricity smart meters to estimate annual electricity bills for a whole year. We develop a method for back-filling data smart meter for up to six missing months for users who have less than one year of smart meter data, ensuring reliable estimates of annual consumption. We identify five distinct electricity consumption user profiles for homes based on day, night, and peak usage patterns, highlighting the economic advantages of Time-of-Use (ToU) tariffs over fixed tariffs for most users, especially those with higher nighttime consumption. Ultimately, the results of this study empowers consumers to manage their energy use effectively and to make informed choices regarding electricity tariff plans.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03574v1-abstract-full').style.display = 'none'; document.getElementById('2412.03574v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 7 figures, 4 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03573">arXiv:2412.03573</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03573">pdf</a>, <a href="https://arxiv.org/format/2412.03573">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Improving Tool Retrieval by Leveraging Large Language Models for Query Generation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kachuee%2C+M">Mohammad Kachuee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahuja%2C+S">Sarthak Ahuja</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+V">Vaibhav Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+P">Puyang Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+X">Xiaohu Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03573v1-abstract-short" style="display: inline;">
        Using tools by Large Language Models (LLMs) is a promising avenue to extend their reach beyond language or conversational settings. The number of tools can scale to thousands as they enable accessing sensory information, fetching updated factual knowledge, or taking actions in the real world. In such settings, in-context learning by providing a short list of relevant tools in the prompt is a viabl&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03573v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03573v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03573v1-abstract-full" style="display: none;">
        Using tools by Large Language Models (LLMs) is a promising avenue to extend their reach beyond language or conversational settings. The number of tools can scale to thousands as they enable accessing sensory information, fetching updated factual knowledge, or taking actions in the real world. In such settings, in-context learning by providing a short list of relevant tools in the prompt is a viable approach. To retrieve relevant tools, various approaches have been suggested, ranging from simple frequency-based matching to dense embedding-based semantic retrieval. However, such approaches lack the contextual and common-sense understanding required to retrieve the right tools for complex user requests. Rather than increasing the complexity of the retrieval component itself, we propose leveraging LLM understanding to generate a retrieval query. Then, the generated query is embedded and used to find the most relevant tools via a nearest-neighbor search. We investigate three approaches for query generation: zero-shot prompting, supervised fine-tuning on tool descriptions, and alignment learning by iteratively optimizing a reward metric measuring retrieval performance. By conducting extensive experiments on a dataset covering complex and multi-tool scenarios, we show that leveraging LLMs for query generation improves the retrieval for in-domain (seen tools) and out-of-domain (unseen tools) settings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03573v1-abstract-full').style.display = 'none'; document.getElementById('2412.03573v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        COLING 2025
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.02702">arXiv:2412.02702</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.02702">pdf</a>, <a href="https://arxiv.org/format/2412.02702">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fine Tuning Swimming Locomotion Learned from Mosquito Larvae
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rajbhandari%2C+P">Pranav Rajbhandari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dhileep%2C+K">Karthick Dhileep</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ravi%2C+S">Sridhar Ravi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sofge%2C+D">Donald Sofge</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.02702v1-abstract-short" style="display: inline;">
        In prior research, we analyzed the backwards swimming motion of mosquito larvae, parameterized it, and replicated it in a Computational Fluid Dynamics (CFD) model. Since the parameterized swimming motion is copied from observed larvae, it is not necessarily the most efficient locomotion for the model of the swimmer. In this project, we further optimize this copied solution for the swimmer model. W&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.02702v1-abstract-full').style.display = 'inline'; document.getElementById('2412.02702v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.02702v1-abstract-full" style="display: none;">
        In prior research, we analyzed the backwards swimming motion of mosquito larvae, parameterized it, and replicated it in a Computational Fluid Dynamics (CFD) model. Since the parameterized swimming motion is copied from observed larvae, it is not necessarily the most efficient locomotion for the model of the swimmer. In this project, we further optimize this copied solution for the swimmer model. We utilize Reinforcement Learning to guide local parameter updates. Since the majority of the computation cost arises from the CFD model, we additionally train a deep learning model to replicate the forces acting on the swimmer model. We find that this method is effective at performing local search to improve the parameterized swimming locomotion.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.02702v1-abstract-full').style.display = 'none'; document.getElementById('2412.02702v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.02512">arXiv:2412.02512</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.02512">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Pre-Deployment Information Sharing: A Zoning Taxonomy for Precursory Capabilities
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pistillo%2C+M">Matteo Pistillo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stix%2C+C">Charlotte Stix</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.02512v1-abstract-short" style="display: inline;">
        High-impact and potentially dangerous capabilities can and should be broken down into early warning shots long before reaching red lines. Each of these early warning shots should correspond to a precursory capability. Each precursory capability sits on a spectrum indicating its proximity to a final high-impact capability, corresponding to a red line. To meaningfully detect and track capability pro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.02512v1-abstract-full').style.display = 'inline'; document.getElementById('2412.02512v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.02512v1-abstract-full" style="display: none;">
        High-impact and potentially dangerous capabilities can and should be broken down into early warning shots long before reaching red lines. Each of these early warning shots should correspond to a precursory capability. Each precursory capability sits on a spectrum indicating its proximity to a final high-impact capability, corresponding to a red line. To meaningfully detect and track capability progress, we propose a taxonomy of dangerous capability zones (a zoning taxonomy) tied to a staggered information exchange framework that enables relevant bodies to take action accordingly. In the Frontier AI Safety Commitments, signatories commit to sharing more detailed information with trusted actors, including an appointed body, as appropriate (Commitment VII). Building on our zoning taxonomy, this paper makes four recommendations for specifying information sharing as detailed in Commitment VII. (1) Precursory capabilities should be shared as soon as they become known through internal evaluations before deployment. (2) AI Safety Institutes (AISIs) should be the trusted actors appointed to receive and coordinate information on precursory components. (3) AISIs should establish adequate information protection infrastructure and guarantee increased information security as precursory capabilities move through the zones and towards red lines, including, if necessary, by classifying the information on precursory capabilities or marking it as controlled. (4) High-impact capability progress in one geographical region may translate to risk in other regions and necessitates more comprehensive risk assessment internationally. As such, AISIs should exchange information on precursory capabilities with other AISIs, relying on the existing frameworks on international classified exchanges and applying lessons learned from other regulated high-risk sectors.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.02512v1-abstract-full').style.display = 'none'; document.getElementById('2412.02512v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.02145">arXiv:2412.02145</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.02145">pdf</a>, <a href="https://arxiv.org/format/2412.02145">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Effective Mitigations for Systemic Risks from General-Purpose AI
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Uuk%2C+R">Risto Uuk</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brouwer%2C+A">Annemieke Brouwer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schreier%2C+T">Tim Schreier</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dreksler%2C+N">Noemi Dreksler</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pulignano%2C+V">Valeria Pulignano</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bommasani%2C+R">Rishi Bommasani</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.02145v1-abstract-short" style="display: inline;">
        The systemic risks posed by general-purpose AI models are a growing concern, yet the effectiveness of mitigations remains underexplored. Previous research has proposed frameworks for risk mitigation, but has left gaps in our understanding of the perceived effectiveness of measures for mitigating systemic risks. Our study addresses this gap by evaluating how experts perceive different mitigations t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.02145v1-abstract-full').style.display = 'inline'; document.getElementById('2412.02145v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.02145v1-abstract-full" style="display: none;">
        The systemic risks posed by general-purpose AI models are a growing concern, yet the effectiveness of mitigations remains underexplored. Previous research has proposed frameworks for risk mitigation, but has left gaps in our understanding of the perceived effectiveness of measures for mitigating systemic risks. Our study addresses this gap by evaluating how experts perceive different mitigations that aim to reduce the systemic risks of general-purpose AI models. We surveyed 76 experts whose expertise spans AI safety; critical infrastructure; democratic processes; chemical, biological, radiological, and nuclear risks (CBRN); and discrimination and bias. Among 27 mitigations identified through a literature review, we find that a broad range of risk mitigation measures are perceived as effective in reducing various systemic risks and technically feasible by domain experts. In particular, three mitigation measures stand out: safety incident reports and security information sharing, third-party pre-deployment model audits, and pre-deployment risk assessments. These measures show both the highest expert agreement ratings (&gt;60\%) across all four risk areas and are most frequently selected in experts&#39; preferred combinations of measures (&gt;40\%). The surveyed experts highlighted that external scrutiny, proactive evaluation and transparency are key principles for effective mitigation of systemic risks. We provide policy recommendations for implementing the most promising measures, incorporating the qualitative contributions from experts. These insights should inform regulatory frameworks and industry practices for mitigating the systemic risks associated with general-purpose AI.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.02145v1-abstract-full').style.display = 'none'; document.getElementById('2412.02145v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">78 pages, 7 figures, 2 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.01849">arXiv:2412.01849</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.01849">pdf</a>, <a href="https://arxiv.org/format/2412.01849">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Data-centric Machine Learning on Directed Graphs: a Survey
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+H">Henan Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xunkai Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Su%2C+D">Daohan Su</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+J">Junyi Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+R">Rong-Hua Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+G">Guoren Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.01849v1-abstract-short" style="display: inline;">
        In recent years, Graph Neural Networks (GNNs) have made significant advances in processing structured data. However, most of them primarily adopted a model-centric approach, which simplifies graphs by converting it into undirected formats and emphasizes model designs. This approach is inherently constrained in real-world applications due to inevitable information loss in simple undirected graphs a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01849v1-abstract-full').style.display = 'inline'; document.getElementById('2412.01849v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.01849v1-abstract-full" style="display: none;">
        In recent years, Graph Neural Networks (GNNs) have made significant advances in processing structured data. However, most of them primarily adopted a model-centric approach, which simplifies graphs by converting it into undirected formats and emphasizes model designs. This approach is inherently constrained in real-world applications due to inevitable information loss in simple undirected graphs and data-driven model optimization dilemmas associated with exceeding the upper bounds of representational capacity. As a result, there has been a shift toward data-centric methods that prioritize improving graph quality and representation. Specifically, various types of graphs can be derived from naturally structured data, including heterogeneous graphs, hypergraphs, and directed graphs. Among these, directed graphs offer distinct advantages in topological systems by modeling causal relationships, and directed GNNs have been extensively studied in recent years. However, a comprehensive survey of this emerging topic is still lacking. Therefore, we aim to provide a comprehensive review of directed graph learning, with a particular focus on a data-centric perspective. Specifically, we first introduce a novel taxonomy for existing studies. Subsequently, we re-examine these methods from the data-centric perspective, with an emphasis on understanding and improving data representation. It demonstrates that a deep understanding of directed graphs and its quality plays a crucial role in model performance. Additionally, we explore the diverse applications of directed GNNs across 10+ domains, highlighting their broad applicability. Finally, we identify key opportunities and challenges within the field, offering insights that can guide future research and development in directed graph learning.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01849v1-abstract-full').style.display = 'none'; document.getElementById('2412.01849v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">In Progress</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.01840">arXiv:2412.01840</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.01840">pdf</a>, <a href="https://arxiv.org/format/2412.01840">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Zonal Architecture Development with evolution of Artificial Intelligence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shetiya%2C+S+S">Sneha Sudhir Shetiya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vyas%2C+V">Vikas Vyas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Renukuntla%2C+S">Shreyas Renukuntla</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.01840v1-abstract-short" style="display: inline;">
        This paper explains how traditional centralized architectures are transitioning to distributed zonal approaches to address challenges in scalability, reliability, performance, and cost-effectiveness. The role of edge computing and neural networks in enabling sophisticated sensor fusion and decision-making capabilities for autonomous vehicles is examined. Additionally, this paper discusses the impa&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01840v1-abstract-full').style.display = 'inline'; document.getElementById('2412.01840v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.01840v1-abstract-full" style="display: none;">
        This paper explains how traditional centralized architectures are transitioning to distributed zonal approaches to address challenges in scalability, reliability, performance, and cost-effectiveness. The role of edge computing and neural networks in enabling sophisticated sensor fusion and decision-making capabilities for autonomous vehicles is examined. Additionally, this paper discusses the impact of zonal architectures on vehicle diagnostics, power distribution, and smart power management systems. Key design considerations for implementing effective zonal architectures are presented, along with an overview of current challenges and future directions. The objective of this paper is to provide a comprehensive understanding of how zonal architectures are shaping the future of automotive technology, particularly in the context of self-driving vehicles and artificial intelligence integration.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01840v1-abstract-full').style.display = 'none'; document.getElementById('2412.01840v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.01787">arXiv:2412.01787</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.01787">pdf</a>, <a href="https://arxiv.org/format/2412.01787">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Pretrained Reversible Generation as Unsupervised Visual Representation Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xue%2C+R">Rongkun Xue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+J">Jinouwen Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Niu%2C+Y">Yazhe Niu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+D">Dazhong Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+B">Bingqi Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yu Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+J">Jing Yang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.01787v1-abstract-short" style="display: inline;">
        Recent generative models based on score matching and flow matching have significantly advanced generation tasks, but their potential in discriminative tasks remains underexplored. Previous approaches, such as generative classifiers, have not fully leveraged the capabilities of these models for discriminative tasks due to their intricate designs. We propose Pretrained Reversible Generation (PRG), w&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01787v1-abstract-full').style.display = 'inline'; document.getElementById('2412.01787v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.01787v1-abstract-full" style="display: none;">
        Recent generative models based on score matching and flow matching have significantly advanced generation tasks, but their potential in discriminative tasks remains underexplored. Previous approaches, such as generative classifiers, have not fully leveraged the capabilities of these models for discriminative tasks due to their intricate designs. We propose Pretrained Reversible Generation (PRG), which extracts unsupervised representations by reversing the generative process of a pretrained continuous flow model. PRG effectively reuses unsupervised generative models, leveraging their high capacity to serve as robust and generalizable feature extractors for downstream tasks. Our method consistently outperforms prior approaches across multiple benchmarks, achieving state-of-the-art performance among generative model-based methods, including 78\% top-1 accuracy on ImageNet. Extensive ablation studies further validate the effectiveness of our approach.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01787v1-abstract-full').style.display = 'none'; document.getElementById('2412.01787v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.01705">arXiv:2412.01705</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.01705">pdf</a>, <a href="https://arxiv.org/format/2412.01705">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Image and Video Processing">eess.IV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Uncertainty-Aware Regularization for Image-to-Image Translation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Vats%2C+A">Anuja Vats</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farup%2C+I">Ivar Farup</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pedersen%2C+M">Marius Pedersen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Raja%2C+K">Kiran Raja</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.01705v1-abstract-short" style="display: inline;">
        The importance of quantifying uncertainty in deep networks has become paramount for reliable real-world applications. In this paper, we propose a method to improve uncertainty estimation in medical Image-to-Image (I2I) translation. Our model integrates aleatoric uncertainty and employs Uncertainty-Aware Regularization (UAR) inspired by simple priors to refine uncertainty estimates and enhance reco&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01705v1-abstract-full').style.display = 'inline'; document.getElementById('2412.01705v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.01705v1-abstract-full" style="display: none;">
        The importance of quantifying uncertainty in deep networks has become paramount for reliable real-world applications. In this paper, we propose a method to improve uncertainty estimation in medical Image-to-Image (I2I) translation. Our model integrates aleatoric uncertainty and employs Uncertainty-Aware Regularization (UAR) inspired by simple priors to refine uncertainty estimates and enhance reconstruction quality. We show that by leveraging simple priors on parameters, our approach captures more robust uncertainty maps, effectively refining them to indicate precisely where the network encounters difficulties, while being less affected by noise. Our experiments demonstrate that UAR not only improves translation performance, but also provides better uncertainty estimations, particularly in the presence of noise and artifacts. We validate our approach using two medical imaging datasets, showcasing its effectiveness in maintaining high confidence in familiar regions while accurately identifying areas of uncertainty in novel/ambiguous scenarios.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01705v1-abstract-full').style.display = 'none'; document.getElementById('2412.01705v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted WACV 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.01622">arXiv:2412.01622</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.01622">pdf</a>, <a href="https://arxiv.org/format/2412.01622">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Image Forgery Localization via Guided Noise and Multi-Scale Feature Aggregation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Niu%2C+Y">Yakun Niu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+P">Pei Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+L">Lei Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tan%2C+L">Lei Tan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yingjian Chen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.01622v1-abstract-short" style="display: inline;">
        Image Forgery Localization (IFL) technology aims to detect and locate the forged areas in an image, which is very important in the field of digital forensics. However, existing IFL methods suffer from feature degradation during training using multi-layer convolutions or the self-attention mechanism, and perform poorly in detecting small forged regions and in robustness against post-processing. To&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01622v1-abstract-full').style.display = 'inline'; document.getElementById('2412.01622v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.01622v1-abstract-full" style="display: none;">
        Image Forgery Localization (IFL) technology aims to detect and locate the forged areas in an image, which is very important in the field of digital forensics. However, existing IFL methods suffer from feature degradation during training using multi-layer convolutions or the self-attention mechanism, and perform poorly in detecting small forged regions and in robustness against post-processing. To tackle these, we propose a guided and multi-scale feature aggregated network for IFL. Spectifically, in order to comprehensively learn the noise feature under different types of forgery, we develop an effective noise extraction module in a guided way. Then, we design a Feature Aggregation Module (FAM) that uses dynamic convolution to adaptively aggregate RGB and noise features over multiple scales. Moreover, we propose an Atrous Residual Pyramid Module (ARPM) to enhance features representation and capture both global and local features using different receptive fields to improve the accuracy and robustness of forgery localization. Expensive experiments on 5 public datasets have shown that our proposed model outperforms several the state-of-the-art methods, specially on small region forged image.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01622v1-abstract-full').style.display = 'none'; document.getElementById('2412.01622v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">36 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00661">arXiv:2412.00661</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00661">pdf</a>, <a href="https://arxiv.org/format/2412.00661">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Anand%2C+E">Emile Anand</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karmarkar%2C+I">Ishani Karmarkar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qu%2C+G">Guannan Qu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00661v1-abstract-short" style="display: inline;">
        Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging due to the fact that the size of the joint state and action spaces are exponentially large in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm \texttt{SUBSAMPLE-MFQ}&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00661v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00661v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00661v1-abstract-full" style="display: none;">
        Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging due to the fact that the size of the joint state and action spaces are exponentially large in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm \texttt{SUBSAMPLE-MFQ} (\textbf{Subsample}-\textbf{M}ean-\textbf{F}ield-\textbf{Q}-learning) and a decentralized randomized policy for a system with $n$ agents. For $k\leq n$, our algorithm system learns a policy for the system in time polynomial in $k$. We show that this learned policy converges to the optimal policy in the order of $\tilde{O}(1/\sqrt{k})$ as the number of subsampled agents $k$ increases. We validate our method empirically on Gaussian squeeze and global exploration settings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00661v1-abstract-full').style.display = 'none'; document.getElementById('2412.00661v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">48 pages. 7 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00657">arXiv:2412.00657</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00657">pdf</a>, <a href="https://arxiv.org/format/2412.00657">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Improving Vietnamese Legal Document Retrieval using Synthetic Data
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tien%2C+S+P">Son Pham Tien</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Doan%2C+H+N">Hieu Nguyen Doan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dai%2C+A+N">An Nguyen Dai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Viet%2C+S+D">Sang Dinh Viet</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00657v1-abstract-short" style="display: inline;">
        In the field of legal information retrieval, effective embedding-based models are essential for accurate question-answering systems. However, the scarcity of large annotated datasets poses a significant challenge, particularly for Vietnamese legal texts. To address this issue, we propose a novel approach that leverages large language models to generate high-quality, diverse synthetic queries for V&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00657v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00657v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00657v1-abstract-full" style="display: none;">
        In the field of legal information retrieval, effective embedding-based models are essential for accurate question-answering systems. However, the scarcity of large annotated datasets poses a significant challenge, particularly for Vietnamese legal texts. To address this issue, we propose a novel approach that leverages large language models to generate high-quality, diverse synthetic queries for Vietnamese legal passages. This synthetic data is then used to pre-train retrieval models, specifically bi-encoder and ColBERT, which are further fine-tuned using contrastive loss with mined hard negatives. Our experiments demonstrate that these enhancements lead to strong improvement in retrieval accuracy, validating the effectiveness of synthetic data and pre-training techniques in overcoming the limitations posed by the lack of large labeled datasets in the Vietnamese legal domain.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00657v1-abstract-full').style.display = 'none'; document.getElementById('2412.00657v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00653">arXiv:2412.00653</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00653">pdf</a>, <a href="https://arxiv.org/format/2412.00653">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Predictive Inference With Fast Feature Conformal Prediction
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+Z">Zihao Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+B">Boyuan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wen%2C+C">Chuan Wen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Teng%2C+J">Jiaye Teng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00653v1-abstract-short" style="display: inline;">
        Conformal prediction is widely adopted in uncertainty quantification, due to its post-hoc, distribution-free, and model-agnostic properties. In the realm of modern deep learning, researchers have proposed Feature Conformal Prediction (FCP), which deploys conformal prediction in a feature space, yielding reduced band lengths. However, the practical utility of FCP is limited due to the time-consumin&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00653v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00653v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00653v1-abstract-full" style="display: none;">
        Conformal prediction is widely adopted in uncertainty quantification, due to its post-hoc, distribution-free, and model-agnostic properties. In the realm of modern deep learning, researchers have proposed Feature Conformal Prediction (FCP), which deploys conformal prediction in a feature space, yielding reduced band lengths. However, the practical utility of FCP is limited due to the time-consuming non-linear operations required to transform confidence bands from feature space to output space. In this paper, we introduce Fast Feature Conformal Prediction (FFCP), which features a novel non-conformity score and is convenient for practical applications. FFCP serves as a fast version of FCP, in that it equivalently employs a Taylor expansion to approximate the aforementioned non-linear operations in FCP. Empirical validations showcase that FFCP performs comparably with FCP (both outperforming the vanilla version) while achieving a significant reduction in computational time by approximately 50x. The code is available at https://github.com/ElvisWang1111/FastFeatureCP
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00653v1-abstract-full').style.display = 'none'; document.getElementById('2412.00653v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00631">arXiv:2412.00631</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00631">pdf</a>, <a href="https://arxiv.org/format/2412.00631">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Y">Yang Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Huayi Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiao%2C+Y">Yizheng Jiao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+L">Lin Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+X">Xiaozhong Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+J">Jinhong Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+D">Dongyu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+D">Dezhi Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+W">Wei Xu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00631v1-abstract-short" style="display: inline;">
        Instruction tuning has underscored the significant potential of large language models (LLMs) in producing more human-controllable and effective outputs in various domains. In this work, we focus on the data selection problem for task-specific instruction tuning of LLMs. Prevailing methods primarily rely on the crafted similarity metrics to select training data that aligns with the test data distri&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00631v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00631v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00631v1-abstract-full" style="display: none;">
        Instruction tuning has underscored the significant potential of large language models (LLMs) in producing more human-controllable and effective outputs in various domains. In this work, we focus on the data selection problem for task-specific instruction tuning of LLMs. Prevailing methods primarily rely on the crafted similarity metrics to select training data that aligns with the test data distribution. The goal is to minimize instruction tuning loss on the test data, ultimately improving performance on the target task. However, it has been widely observed that instruction tuning loss (i.e., cross-entropy loss for next token prediction) in LLMs often fails to exhibit a monotonic relationship with actual task performance. This misalignment undermines the effectiveness of current data selection methods for task-specific instruction tuning. To address this issue, we introduce ROSE, a novel Reward-Oriented inStruction data sElection method which leverages pairwise preference loss as a reward signal to optimize data selection for task-specific instruction tuning. Specifically, ROSE adapts an influence formulation to approximate the influence of training data points relative to a few-shot preference validation set to select the most task-related training data points. Experimental results show that by selecting just 5% of the training data using ROSE, our approach can achieve competitive results compared to fine-tuning with the full training dataset, and it surpasses other state-of-the-art data selection methods for task-specific instruction tuning. Our qualitative analysis further confirms the robust generalizability of our method across multiple benchmark datasets and diverse model architectures.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00631v1-abstract-full').style.display = 'none'; document.getElementById('2412.00631v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00627">arXiv:2412.00627</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00627">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ARChef: An iOS-Based Augmented Reality Cooking Assistant Powered by Multimodal Gemini LLM
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Vir%2C+R">Rithik Vir</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Madinei%2C+P">Parsa Madinei</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00627v1-abstract-short" style="display: inline;">
        Cooking meals can be difficult, causing many to use cookbooks and online recipes, which results in missing ingredients, nutritional hazards, unsatisfactory meals. Using Augmented Reality (AR) can address this issue, however, current AR cooking applications have poor user interfaces and limited accessibility. This paper proposes a prototype of an iOS application that integrates AR and Computer Visi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00627v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00627v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00627v1-abstract-full" style="display: none;">
        Cooking meals can be difficult, causing many to use cookbooks and online recipes, which results in missing ingredients, nutritional hazards, unsatisfactory meals. Using Augmented Reality (AR) can address this issue, however, current AR cooking applications have poor user interfaces and limited accessibility. This paper proposes a prototype of an iOS application that integrates AR and Computer Vision (CV) into the cooking process. We leverage Google&#39;s Gemini Large Language Model (LLM) to identify ingredients based on the camera&#39;s field of vision, and generate recipe choices with their nutritional information. Additionally, this application uses Apple&#39;s ARKit to create an AR user interface compatible with iOS devices. Users can personalize their meal suggestions by inputting their dietary preferences and rating each meal. The application&#39;s effectiveness is evaluated through user experience surveys. This application contributes to the field of accessible cooking assistance technologies, aiming to reduce food wastage and improve the meal planning experience.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00627v1-abstract-full').style.display = 'none'; document.getElementById('2412.00627v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00622">arXiv:2412.00622</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00622">pdf</a>, <a href="https://arxiv.org/format/2412.00622">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Visual Modality Prompt for Adapting Vision-Language Object Detectors
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Medeiros%2C+H+R">Heitor R. Medeiros</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Belal%2C+A">Atif Belal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Muralidharan%2C+S">Srikanth Muralidharan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Granger%2C+E">Eric Granger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pedersoli%2C+M">Marco Pedersoli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00622v1-abstract-short" style="display: inline;">
        The zero-shot performance of object detectors degrades when tested on different modalities, such as infrared and depth. While recent work has explored image translation techniques to adapt detectors to new modalities, these methods are limited to a single modality and apply only to traditional detectors. Recently, vision-language detectors, such as YOLO-World and Grounding DINO, have shown promisi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00622v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00622v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00622v1-abstract-full" style="display: none;">
        The zero-shot performance of object detectors degrades when tested on different modalities, such as infrared and depth. While recent work has explored image translation techniques to adapt detectors to new modalities, these methods are limited to a single modality and apply only to traditional detectors. Recently, vision-language detectors, such as YOLO-World and Grounding DINO, have shown promising zero-shot capabilities, however, they have not yet been adapted for other visual modalities. Traditional fine-tuning approaches tend to compromise the zero-shot capabilities of the detectors. The visual prompt strategies commonly used for classification with vision-language models apply the same linear prompt translation to each image making them less effective. To address these limitations, we propose ModPrompt, a visual prompt strategy to adapt vision-language detectors to new modalities without degrading zero-shot performance. In particular, an encoder-decoder visual prompt strategy is proposed, further enhanced by the integration of inference-friendly task residuals, facilitating more robust adaptation. Empirically, we benchmark our method for modality adaptation on two vision-language detectors, YOLO-World and Grounding DINO, and on challenging infrared (LLVIP, FLIR) and depth (NYUv2) data, achieving performance comparable to full fine-tuning while preserving the model&#39;s zero-shot capability. Our code is available at: https://github.com/heitorrapela/ModPrompt
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00622v1-abstract-full').style.display = 'none'; document.getElementById('2412.00622v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00621">arXiv:2412.00621</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00621">pdf</a>, <a href="https://arxiv.org/format/2412.00621">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exposing LLM Vulnerabilities: Adversarial Scam Detection and Performance
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chang%2C+C">Chen-Wei Chang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sarkar%2C+S">Shailik Sarkar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mitra%2C+S">Shutonu Mitra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Salemi%2C+H">Hossein Salemi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Purohit%2C+H">Hemant Purohit</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+F">Fengxiu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hong%2C+M">Michin Hong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cho%2C+J">Jin-Hee Cho</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+C">Chang-Tien Lu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00621v1-abstract-short" style="display: inline;">
        Can we trust Large Language Models (LLMs) to accurately predict scam? This paper investigates the vulnerabilities of LLMs when facing adversarial scam messages for the task of scam detection. We addressed this issue by creating a comprehensive dataset with fine-grained labels of scam messages, including both original and adversarial scam messages. The dataset extended traditional binary classes fo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00621v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00621v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00621v1-abstract-full" style="display: none;">
        Can we trust Large Language Models (LLMs) to accurately predict scam? This paper investigates the vulnerabilities of LLMs when facing adversarial scam messages for the task of scam detection. We addressed this issue by creating a comprehensive dataset with fine-grained labels of scam messages, including both original and adversarial scam messages. The dataset extended traditional binary classes for the scam detection task into more nuanced scam types. Our analysis showed how adversarial examples took advantage of vulnerabilities of a LLM, leading to high misclassification rate. We evaluated the performance of LLMs on these adversarial scam messages and proposed strategies to improve their robustness.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00621v1-abstract-full').style.display = 'none'; document.getElementById('2412.00621v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">4 pages, 2024 IEEE International Conference on Big Data workshop BigEACPS 2024</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00596">arXiv:2412.00596</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00596">pdf</a>, <a href="https://arxiv.org/format/2412.00596">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PhyT2V: LLM-Guided Iterative Self-Refinement for Physics-Grounded Text-to-Video Generation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xue%2C+Q">Qiyao Xue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yin%2C+X">Xiangyu Yin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+B">Boyuan Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+W">Wei Gao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00596v1-abstract-short" style="display: inline;">
        Text-to-video (T2V) generation has been recently enabled by transformer-based diffusion models, but current T2V models lack capabilities in adhering to the real-world common knowledge and physical rules, due to their limited understanding of physical realism and deficiency in temporal modeling. Existing solutions are either data-driven or require extra model inputs, but cannot be generalizable to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00596v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00596v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00596v1-abstract-full" style="display: none;">
        Text-to-video (T2V) generation has been recently enabled by transformer-based diffusion models, but current T2V models lack capabilities in adhering to the real-world common knowledge and physical rules, due to their limited understanding of physical realism and deficiency in temporal modeling. Existing solutions are either data-driven or require extra model inputs, but cannot be generalizable to out-of-distribution domains. In this paper, we present PhyT2V, a new data-independent T2V technique that expands the current T2V model&#39;s capability of video generation to out-of-distribution domains, by enabling chain-of-thought and step-back reasoning in T2V prompting. Our experiments show that PhyT2V improves existing T2V models&#39; adherence to real-world physical rules by 2.3x, and achieves 35% improvement compared to T2V prompt enhancers. The source codes are available at: https://github.com/pittisl/PhyT2V.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00596v1-abstract-full').style.display = 'none'; document.getElementById('2412.00596v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">30 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00592">arXiv:2412.00592</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00592">pdf</a>, <a href="https://arxiv.org/format/2412.00592">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Generative LiDAR Editing with Controllable Novel Object Layouts
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ho%2C+S">Shing-Hei Ho</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Thach%2C+B">Bao Thach</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+M">Minghan Zhu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00592v1-abstract-short" style="display: inline;">
        We propose a framework to edit real-world Lidar scans with novel object layouts while preserving a realistic background environment. Compared to the synthetic data generation frameworks where Lidar point clouds are generated from scratch, our framework focuses on new scenario generation in a given background environment, and our method also provides labels for the generated data. This approach ens&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00592v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00592v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00592v1-abstract-full" style="display: none;">
        We propose a framework to edit real-world Lidar scans with novel object layouts while preserving a realistic background environment. Compared to the synthetic data generation frameworks where Lidar point clouds are generated from scratch, our framework focuses on new scenario generation in a given background environment, and our method also provides labels for the generated data. This approach ensures the generated data remains relevant to the specific environment, aiding both the development and the evaluation of algorithms in real-world scenarios. Compared with novel view synthesis, our framework allows the creation of counterfactual scenarios with significant changes in the object layout and does not rely on multi-frame optimization. In our framework, the object removal and insertion are supported by generative background inpainting and object point cloud completion, and the entire pipeline is built upon spherical voxelization, which realizes the correct Lidar projective geometry by construction. Experiments show that our framework generates realistic Lidar scans with object layout changes and benefits the development of Lidar-based self-driving systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00592v1-abstract-full').style.display = 'none'; document.getElementById('2412.00592v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to IEEE International Conference on Robotics and Automation (ICRA). 6 pages, 7 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00591">arXiv:2412.00591</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00591">pdf</a>, <a href="https://arxiv.org/format/2412.00591">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Audio Atlas: Visualizing and Exploring Audio Datasets
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lanzend%C3%B6rfer%2C+L+A">Luca A. Lanzendrfer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gr%C3%B6tschla%2C+F">Florian Grtschla</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Valizada%2C+U">Uzeyir Valizada</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wattenhofer%2C+R">Roger Wattenhofer</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00591v1-abstract-short" style="display: inline;">
        We introduce Audio Atlas, an interactive web application for visualizing audio data using text-audio embeddings. Audio Atlas is designed to facilitate the exploration and analysis of audio datasets using a contrastive embedding model and a vector database for efficient data management and semantic search. The system maps audio embeddings into a two-dimensional space and leverages DeepScatter for d&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00591v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00591v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00591v1-abstract-full" style="display: none;">
        We introduce Audio Atlas, an interactive web application for visualizing audio data using text-audio embeddings. Audio Atlas is designed to facilitate the exploration and analysis of audio datasets using a contrastive embedding model and a vector database for efficient data management and semantic search. The system maps audio embeddings into a two-dimensional space and leverages DeepScatter for dynamic visualization. Designed for extensibility, Audio Atlas allows easy integration of new datasets, enabling users to better understand their audio data and identify both patterns and outliers. We open-source the codebase of Audio Atlas, and provide an initial implementation containing various audio and music datasets.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00591v1-abstract-full').style.display = 'none'; document.getElementById('2412.00591v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Extended Abstract at ISMIR 2024</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00560">arXiv:2412.00560</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00560">pdf</a>, <a href="https://arxiv.org/format/2412.00560">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Friend or Foe? Harnessing Controllable Overfitting for Anomaly Detection
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Qian%2C+L">Long Qian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+B">Bingke Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yingying Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+M">Ming Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+J">Jinqiao Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00560v1-abstract-short" style="display: inline;">
        Overfitting has long been stigmatized as detrimental to model performance, especially in the context of anomaly detection. Our work challenges this conventional view by introducing a paradigm shift, recasting overfitting as a controllable and strategic mechanism for enhancing model discrimination capabilities. In this paper, we present Controllable Overfitting-based Anomaly Detection (COAD), a nov&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00560v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00560v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00560v1-abstract-full" style="display: none;">
        Overfitting has long been stigmatized as detrimental to model performance, especially in the context of anomaly detection. Our work challenges this conventional view by introducing a paradigm shift, recasting overfitting as a controllable and strategic mechanism for enhancing model discrimination capabilities. In this paper, we present Controllable Overfitting-based Anomaly Detection (COAD), a novel framework designed to leverage overfitting for optimized anomaly detection. We propose the Aberrance Retention Quotient (ARQ), a novel metric that systematically quantifies the extent of overfitting, enabling the identification of an optimal &#34;golden overfitting interval.&#34; Within this interval, overfitting is leveraged to significantly amplify the model&#39;s sensitivity to anomalous patterns, while preserving generalization to normal samples. Additionally, we present the Relative Anomaly Distribution Index (RADI), an innovative metric designed to complement AUROC pixel by providing a more versatile and theoretically robust framework for assessing model performance. RADI leverages ARQ to track and evaluate how overfitting impacts anomaly detection, offering an integrated approach to understanding the relationship between overfitting dynamics and model efficacy. Our theoretical work also rigorously validates the use of Gaussian noise in pseudo anomaly synthesis, providing the foundation for its broader applicability across diverse domains. Empirical evaluations demonstrate that our controllable overfitting method not only achieves State of the Art (SOTA) performance in both one-class and multi-class anomaly detection tasks but also redefines overfitting from a modeling challenge into a powerful tool for optimizing anomaly detection.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00560v1-abstract-full').style.display = 'none'; document.getElementById('2412.00560v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00559">arXiv:2412.00559</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00559">pdf</a>, <a href="https://arxiv.org/format/2412.00559">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Polish Medical Exams: A new dataset for cross-lingual medical knowledge transfer assessment
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Grzybowski%2C+%C5%81">ukasz Grzybowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pokrywka%2C+J">Jakub Pokrywka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ciesi%C3%B3%C5%82ka%2C+M">Micha Ciesika</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kaczmarek%2C+J+I">Jeremi I. Kaczmarek</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kubis%2C+M">Marek Kubis</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00559v1-abstract-short" style="display: inline;">
        Large Language Models (LLMs) have demonstrated significant potential in handling specialized tasks, including medical problem-solving. However, most studies predominantly focus on English-language contexts. This study introduces a novel benchmark dataset based on Polish medical licensing and specialization exams (LEK, LDEK, PES) taken by medical doctor candidates and practicing doctors pursuing sp&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00559v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00559v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00559v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) have demonstrated significant potential in handling specialized tasks, including medical problem-solving. However, most studies predominantly focus on English-language contexts. This study introduces a novel benchmark dataset based on Polish medical licensing and specialization exams (LEK, LDEK, PES) taken by medical doctor candidates and practicing doctors pursuing specialization. The dataset was web-scraped from publicly available resources provided by the Medical Examination Center and the Chief Medical Chamber. It comprises over 24,000 exam questions, including a subset of parallel Polish-English corpora, where the English portion was professionally translated by the examination center for foreign candidates. By creating a structured benchmark from these existing exam questions, we systematically evaluate state-of-the-art LLMs, including general-purpose, domain-specific, and Polish-specific models, and compare their performance against human medical students. Our analysis reveals that while models like GPT-4o achieve near-human performance, significant challenges persist in cross-lingual translation and domain-specific understanding. These findings underscore disparities in model performance across languages and medical specialties, highlighting the limitations and ethical considerations of deploying LLMs in clinical practice.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00559v1-abstract-full').style.display = 'none'; document.getElementById('2412.00559v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00557">arXiv:2412.00557</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00557">pdf</a>, <a href="https://arxiv.org/format/2412.00557">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Blind Inverse Problem Solving Made Easy by Text-to-Image Latent Diffusion
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dontas%2C+M">Michail Dontas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=He%2C+Y">Yutong He</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Murata%2C+N">Naoki Murata</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kolter%2C+J+Z">J. Zico Kolter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00557v1-abstract-short" style="display: inline;">
        Blind inverse problems, where both the target data and forward operator are unknown, are crucial to many computer vision applications. Existing methods often depend on restrictive assumptions such as additional training, operator linearity, or narrow image distributions, thus limiting their generalizability. In this work, we present LADiBI, a training-free framework that uses large-scale text-to-i&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00557v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00557v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00557v1-abstract-full" style="display: none;">
        Blind inverse problems, where both the target data and forward operator are unknown, are crucial to many computer vision applications. Existing methods often depend on restrictive assumptions such as additional training, operator linearity, or narrow image distributions, thus limiting their generalizability. In this work, we present LADiBI, a training-free framework that uses large-scale text-to-image diffusion models to solve blind inverse problems with minimal assumptions. By leveraging natural language prompts, LADiBI jointly models priors for both the target image and operator, allowing for flexible adaptation across a variety of tasks. Additionally, we propose a novel posterior sampling approach that combines effective operator initialization with iterative refinement, enabling LADiBI to operate without predefined operator forms. Our experiments show that LADiBI is capable of solving a broad range of image restoration tasks, including both linear and nonlinear problems, on diverse target image distributions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00557v1-abstract-full').style.display = 'none'; document.getElementById('2412.00557v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00554">arXiv:2412.00554</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00554">pdf</a>, <a href="https://arxiv.org/format/2412.00554">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+Y">Yue Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di+Eugenio%2C+B">Barbara Di Eugenio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+L">Lu Cheng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00554v1-abstract-short" style="display: inline;">
        This paper studies the performance of large language models (LLMs), particularly regarding demographic fairness, in solving real-world healthcare tasks. We evaluate state-of-the-art LLMs with three prevalent learning frameworks across six diverse healthcare tasks and find significant challenges in applying LLMs to real-world healthcare tasks and persistent fairness issues across demographic groups&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00554v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00554v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00554v1-abstract-full" style="display: none;">
        This paper studies the performance of large language models (LLMs), particularly regarding demographic fairness, in solving real-world healthcare tasks. We evaluate state-of-the-art LLMs with three prevalent learning frameworks across six diverse healthcare tasks and find significant challenges in applying LLMs to real-world healthcare tasks and persistent fairness issues across demographic groups. We also find that explicitly providing demographic information yields mixed results, while LLM&#39;s ability to infer such details raises concerns about biased health predictions. Utilizing LLMs as autonomous agents with access to up-to-date guidelines does not guarantee performance improvement. We believe these findings reveal the critical limitations of LLMs in healthcare fairness and the urgent need for specialized research in this area.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00554v1-abstract-full').style.display = 'none'; document.getElementById('2412.00554v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to the main conference of COLING 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00547">arXiv:2412.00547</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00547">pdf</a>, <a href="https://arxiv.org/format/2412.00547">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Motion Dreamer: Realizing Physically Coherent Video Generation through Scene-Aware Motion Reasoning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+T">Tianshuo Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Z">Zhifei Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+L">Leyi Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+H">Hao Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yuying Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+L">Lihui Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+B">Bingbing Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yingcong Chen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00547v1-abstract-short" style="display: inline;">
        Recent numerous video generation models, also known as world models, have demonstrated the ability to generate plausible real-world videos. However, many studies have shown that these models often produce motion results lacking logical or physical coherence. In this paper, we revisit video generation models and find that single-stage approaches struggle to produce high-quality results while mainta&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00547v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00547v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00547v1-abstract-full" style="display: none;">
        Recent numerous video generation models, also known as world models, have demonstrated the ability to generate plausible real-world videos. However, many studies have shown that these models often produce motion results lacking logical or physical coherence. In this paper, we revisit video generation models and find that single-stage approaches struggle to produce high-quality results while maintaining coherent motion reasoning. To address this issue, we propose \textbf{Motion Dreamer}, a two-stage video generation framework. In Stage I, the model generates an intermediate motion representation-such as a segmentation map or depth map-based on the input image and motion conditions, focusing solely on the motion itself. In Stage II, the model uses this intermediate motion representation as a condition to generate a high-detail video. By decoupling motion reasoning from high-fidelity video synthesis, our approach allows for more accurate and physically plausible motion generation. We validate the effectiveness of our approach on the Physion dataset and in autonomous driving scenarios. For example, given a single push, our model can synthesize the sequential toppling of a set of dominoes. Similarly, by varying the movements of ego-cars, our model can produce different effects on other vehicles. Our work opens new avenues in creating models that can reason about physical interactions in a more coherent and realistic manner.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00547v1-abstract-full').style.display = 'none'; document.getElementById('2412.00547v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00539">arXiv:2412.00539</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00539">pdf</a>, <a href="https://arxiv.org/format/2412.00539">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        TextClass Benchmark: A Continuous Elo Rating of LLMs in Social Sciences
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gonz%C3%A1lez-Bustamante%2C+B">Bastin Gonzlez-Bustamante</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00539v1-abstract-short" style="display: inline;">
        The TextClass Benchmark project is an ongoing, continuous benchmarking process that aims to provide a comprehensive, fair, and dynamic evaluation of LLMs and transformers for text classification tasks. This evaluation spans various domains and languages in social sciences disciplines engaged in NLP and text-as-data approach. The leaderboards present performance metrics and relative ranking using a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00539v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00539v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00539v1-abstract-full" style="display: none;">
        The TextClass Benchmark project is an ongoing, continuous benchmarking process that aims to provide a comprehensive, fair, and dynamic evaluation of LLMs and transformers for text classification tasks. This evaluation spans various domains and languages in social sciences disciplines engaged in NLP and text-as-data approach. The leaderboards present performance metrics and relative ranking using a tailored Elo rating system. With each leaderboard cycle, novel models are added, fixed test sets can be replaced for unseen, equivalent data to test generalisation power, ratings are updated, and a Meta-Elo leaderboard combines and weights domain-specific leaderboards. This article presents the rationale and motivation behind the project, explains the Elo rating system in detail, and estimates Meta-Elo across different classification tasks in social science disciplines. We also present a snapshot of the first cycle of classification tasks on incivility data in Chinese, English, German and Russian. This ongoing benchmarking process includes not only additional languages such as Arabic, Hindi, and Spanish but also a classification of policy agenda topics, misinformation, among others.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00539v1-abstract-full').style.display = 'none'; document.getElementById('2412.00539v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Working paper: 6 pages, 2 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50 (Primary) 91F10; 91F20 (Secondary)
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00534">arXiv:2412.00534</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00534">pdf</a>, <a href="https://arxiv.org/format/2412.00534">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Fault Tolerance in Multi-Agent Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+Y">Yuchen Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pei%2C+H">Huaxin Pei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+L">Liang Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">Yi Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yao%2C+D">Danya Yao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00534v1-abstract-short" style="display: inline;">
        Agent faults pose a significant threat to the performance of multi-agent reinforcement learning (MARL) algorithms, introducing two key challenges. First, agents often struggle to extract critical information from the chaotic state space created by unexpected faults. Second, transitions recorded before and after faults in the replay buffer affect training unevenly, leading to a sample imbalance pro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00534v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00534v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00534v1-abstract-full" style="display: none;">
        Agent faults pose a significant threat to the performance of multi-agent reinforcement learning (MARL) algorithms, introducing two key challenges. First, agents often struggle to extract critical information from the chaotic state space created by unexpected faults. Second, transitions recorded before and after faults in the replay buffer affect training unevenly, leading to a sample imbalance problem. To overcome these challenges, this paper enhances the fault tolerance of MARL by combining optimized model architecture with a tailored training data sampling strategy. Specifically, an attention mechanism is incorporated into the actor and critic networks to automatically detect faults and dynamically regulate the attention given to faulty agents. Additionally, a prioritization mechanism is introduced to selectively sample transitions critical to current training needs. To further support research in this area, we design and open-source a highly decoupled code platform for fault-tolerant MARL, aimed at improving the efficiency of studying related problems. Experimental results demonstrate the effectiveness of our method in handling various types of faults, faults occurring in any agent, and faults arising at random times.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00534v1-abstract-full').style.display = 'none'; document.getElementById('2412.00534v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">14 pages, 13 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00526">arXiv:2412.00526</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00526">pdf</a>, <a href="https://arxiv.org/format/2412.00526">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Human Action CLIPS: Detecting AI-generated Human Motion
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bohacek%2C+M">Matyas Bohacek</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farid%2C+H">Hany Farid</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00526v1-abstract-short" style="display: inline;">
        Full-blown AI-generated video generation continues its journey through the uncanny valley to produce content that is perceptually indistinguishable from reality. Intermixed with many exciting and creative applications are malicious applications that harm individuals, organizations, and democracies. We describe an effective and robust technique for distinguishing real from AI-generated human motion&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00526v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00526v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00526v1-abstract-full" style="display: none;">
        Full-blown AI-generated video generation continues its journey through the uncanny valley to produce content that is perceptually indistinguishable from reality. Intermixed with many exciting and creative applications are malicious applications that harm individuals, organizations, and democracies. We describe an effective and robust technique for distinguishing real from AI-generated human motion. This technique leverages a multi-modal semantic embedding, making it robust to the types of laundering that typically confound more low- to mid-level approaches. This method is evaluated against a custom-built dataset of video clips with human actions generated by seven text-to-video AI models and matching real footage.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00526v1-abstract-full').style.display = 'none'; document.getElementById('2412.00526v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00508">arXiv:2412.00508</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00508">pdf</a>, <a href="https://arxiv.org/format/2412.00508">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Graph-to-SFILES: Control structure prediction from process topologies using generative artificial intelligence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Balhorn%2C+L+S">Lukas Schulze Balhorn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Degens%2C+K">Kevin Degens</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schweidtmann%2C+A+M">Artur M. Schweidtmann</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00508v1-abstract-short" style="display: inline;">
        Control structure design is an important but tedious step in P&amp;ID development. Generative artificial intelligence (AI) promises to reduce P&amp;ID development time by supporting engineers. Previous research on generative AI in chemical process design mainly represented processes by sequences. However, graphs offer a promising alternative because of their permutation invariance. We propose the Graph-to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00508v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00508v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00508v1-abstract-full" style="display: none;">
        Control structure design is an important but tedious step in P&amp;ID development. Generative artificial intelligence (AI) promises to reduce P&amp;ID development time by supporting engineers. Previous research on generative AI in chemical process design mainly represented processes by sequences. However, graphs offer a promising alternative because of their permutation invariance. We propose the Graph-to-SFILES model, a generative AI method to predict control structures from flowsheet topologies. The Graph-to-SFILES model takes the flowsheet topology as a graph input and returns a control-extended flowsheet as a sequence in the SFILES 2.0 notation. We compare four different graph encoder architectures, one of them being a graph neural network (GNN) proposed in this work. The Graph-to-SFILES model achieves a top-5 accuracy of 73.2% when trained on 10,000 flowsheet topologies. In addition, the proposed GNN performs best among the encoder architectures. Compared to a purely sequence-based approach, the Graph-to-SFILES model improves the top-5 accuracy for a relatively small training dataset of 1,000 flowsheets from 0.9% to 28.4%. However, the sequence-based approach performs better on a large-scale dataset of 100,000 flowsheets. These results highlight the potential of graph-based AI models to accelerate P&amp;ID development in small-data regimes but their effectiveness on industry relevant case studies still needs to be investigated.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00508v1-abstract-full').style.display = 'none'; document.getElementById('2412.00508v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00503">arXiv:2412.00503</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00503">pdf</a>, <a href="https://arxiv.org/format/2412.00503">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Homeostazis and Sparsity in Transformer
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kotyuzanskiy%2C+L">Leonid Kotyuzanskiy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Klimov%2C+A">Artem Klimov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00503v1-abstract-short" style="display: inline;">
        The transformer architecture has become an integral part of the field of modern neural networks, playing a crucial role in a variety of tasks, such as text generation, machine translation, image and audio processing, among others. There is also an alternative approach to building intelligent systems, proposed by Jeff Hawkins and inspired by the processes occurring in the neocortex. In our article&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00503v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00503v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00503v1-abstract-full" style="display: none;">
        The transformer architecture has become an integral part of the field of modern neural networks, playing a crucial role in a variety of tasks, such as text generation, machine translation, image and audio processing, among others. There is also an alternative approach to building intelligent systems, proposed by Jeff Hawkins and inspired by the processes occurring in the neocortex. In our article we want to combine some of these ideas and to propose the use of homeostazis mechanisms, such as RFB-kWTA and &#34;Smart&#34; Inhibition, in the attention mechanism of the transformer and at the output of the transformer block, as well as conducting an experiment involving the introduction of sparse distributed representations of the transformer at various points. RFB-kWTA utilizes statistics of layer activations across time to adjust the entire layer, enhancing the values of rare activations while reducing those of frequent ones. &#34;Smart&#34; Inhibition also uses activation statistics to sample sparsity masks, with rarer activation times are more likely to be activated. Our proposed mechanisms significantly outperform the classical transformer 0.2768 BLEU and a model that only makes use of dropout in the attention mechanism and output of the transformer block 0.3007 BLEU, achieving a score of 0.3062 on the Multi30K dataset.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00503v1-abstract-full').style.display = 'none'; document.getElementById('2412.00503v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00488">arXiv:2412.00488</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00488">pdf</a>, <a href="https://arxiv.org/format/2412.00488">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Improved Cleanup and Decoding of Fractional Power Encodings
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bremer%2C+A">Alicia Bremer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Orchard%2C+J">Jeff Orchard</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00488v1-abstract-short" style="display: inline;">
        High-dimensional vectors have been proposed as a neural method for representing information in the brain using Vector Symbolic Algebras (VSAs). While previous work has explored decoding and cleaning up these vectors under the noise that arises during computation, existing methods are limited. Cleanup methods are essential for robust computation within a VSA. However, cleanup methods for continuous&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00488v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00488v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00488v1-abstract-full" style="display: none;">
        High-dimensional vectors have been proposed as a neural method for representing information in the brain using Vector Symbolic Algebras (VSAs). While previous work has explored decoding and cleaning up these vectors under the noise that arises during computation, existing methods are limited. Cleanup methods are essential for robust computation within a VSA. However, cleanup methods for continuous-value encodings are not as effective. In this paper, we present an iterative optimization method to decode and clean up Fourier Holographic Reduced Representation (FHRR) vectors that are encoding continuous values. We combine composite likelihood estimation (CLE) and maximum likelihood estimation (MLE) to ensure convergence to the global optimum. We also demonstrate that this method can effectively decode FHRR vectors under different noise conditions, and show that it outperforms existing methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00488v1-abstract-full').style.display = 'none'; document.getElementById('2412.00488v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T07; 92B20
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00465">arXiv:2412.00465</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00465">pdf</a>, <a href="https://arxiv.org/format/2412.00465">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AgriBench: A Hierarchical Agriculture Benchmark for Multimodal Large Language Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+Y">Yutong Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ryo%2C+M">Masahiro Ryo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00465v1-abstract-short" style="display: inline;">
        We introduce AgriBench, the first agriculture benchmark designed to evaluate MultiModal Large Language Models (MM-LLMs) for agriculture applications. To further address the agriculture knowledge-based dataset limitation problem, we propose MM-LUCAS, a multimodal agriculture dataset, that includes 1,784 landscape images, segmentation masks, depth maps, and detailed annotations (geographical locatio&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00465v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00465v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00465v1-abstract-full" style="display: none;">
        We introduce AgriBench, the first agriculture benchmark designed to evaluate MultiModal Large Language Models (MM-LLMs) for agriculture applications. To further address the agriculture knowledge-based dataset limitation problem, we propose MM-LUCAS, a multimodal agriculture dataset, that includes 1,784 landscape images, segmentation masks, depth maps, and detailed annotations (geographical location, country, date, land cover and land use taxonomic details, quality scores, aesthetic scores, etc), based on the Land Use/Cover Area Frame Survey (LUCAS) dataset, which contains comparable statistics on land use and land cover for the European Union (EU) territory. This work presents a groundbreaking perspective in advancing agriculture MM-LLMs and is still in progress, offering valuable insights for future developments and innovations in specific expert knowledge-based MM-LLMs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00465v1-abstract-full').style.display = 'none'; document.getElementById('2412.00465v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by CVPPA @ECCV2024. Dataset: https://github.com/Yutong-Zhou-cv/AgriBench</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00464">arXiv:2412.00464</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00464">pdf</a>, <a href="https://arxiv.org/ps/2412.00464">ps</a>, <a href="https://arxiv.org/format/2412.00464">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On the Conditions for Domain Stability for Machine Learning: a Mathematical Approach
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pedroza%2C+G">Gabriel Pedroza</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00464v1-abstract-short" style="display: inline;">
        This work proposes a mathematical approach that (re)defines a property of Machine Learning models named stability and determines sufficient conditions to validate it. Machine Learning models are represented as functions, and the characteristics in scope depend upon the domain of the function, what allows us to adopt topological and metric spaces theory as a basis. Finally, this work provides some&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00464v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00464v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00464v1-abstract-full" style="display: none;">
        This work proposes a mathematical approach that (re)defines a property of Machine Learning models named stability and determines sufficient conditions to validate it. Machine Learning models are represented as functions, and the characteristics in scope depend upon the domain of the function, what allows us to adopt topological and metric spaces theory as a basis. Finally, this work provides some equivalences useful to prove and test stability in Machine Learning models. The results suggest that whenever stability is aligned with the notion of function smoothness, then the stability of Machine Learning models primarily depends upon certain topological, measurable properties of the classification sets within the ML model domain.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00464v1-abstract-full').style.display = 'none'; document.getElementById('2412.00464v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages including references, no figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          F.4.1; I.2.0
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00429">arXiv:2412.00429</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00429">pdf</a>, <a href="https://arxiv.org/format/2412.00429">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learner Attentiveness and Engagement Analysis in Online Education Using Computer Vision
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gogawale%2C+S">Sharva Gogawale</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Deshpande%2C+M">Madhura Deshpande</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+P">Parteek Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ben-Gal%2C+I">Irad Ben-Gal</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00429v1-abstract-short" style="display: inline;">
        In recent times, online education and the usage of video-conferencing platforms have experienced massive growth. Due to the limited scope of a virtual classroom, it may become difficult for instructors to analyze learners&#39; attention and comprehension in real time while teaching. In the digital mode of education, it would be beneficial for instructors to have an automated feedback mechanism to be i&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00429v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00429v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00429v1-abstract-full" style="display: none;">
        In recent times, online education and the usage of video-conferencing platforms have experienced massive growth. Due to the limited scope of a virtual classroom, it may become difficult for instructors to analyze learners&#39; attention and comprehension in real time while teaching. In the digital mode of education, it would be beneficial for instructors to have an automated feedback mechanism to be informed regarding learners&#39; attentiveness at any given time. This research presents a novel computer vision-based approach to analyze and quantify learners&#39; attentiveness, engagement, and other affective states within online learning scenarios. This work presents the development of a multiclass multioutput classification method using convolutional neural networks on a publicly available dataset - DAiSEE. A machine learning-based algorithm is developed on top of the classification model that outputs a comprehensive attentiveness index of the learners. Furthermore, an end-to-end pipeline is proposed through which learners&#39; live video feed is processed, providing detailed attentiveness analytics of the learners to the instructors. By comparing the experimental outcomes of the proposed method against those of previous methods, it is demonstrated that the proposed method exhibits better attentiveness detection than state-of-the-art methods. The proposed system is a comprehensive, practical, and real-time solution that is deployable and easy to use. The experimental results also demonstrate the system&#39;s efficiency in gauging learners&#39; attentiveness.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00429v1-abstract-full').style.display = 'none'; document.getElementById('2412.00429v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00427">arXiv:2412.00427</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00427">pdf</a>, <a href="https://arxiv.org/format/2412.00427">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        FreeCond: Free Lunch in the Input Conditions of Text-Guided Inpainting
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hsiao%2C+T">Teng-Fang Hsiao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ruan%2C+B">Bo-Kai Ruan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tsai%2C+S">Sung-Lin Tsai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Y">Yi-Lun Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shuai%2C+H">Hong-Han Shuai</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00427v1-abstract-short" style="display: inline;">
        In this study, we aim to determine and solve the deficiency of Stable Diffusion Inpainting (SDI) in following the instruction of both prompt and mask. Due to the training bias from masking, the inpainting quality is hindered when the prompt instruction and image condition are not related. Therefore, we conduct a detailed analysis of the internal representations learned by SDI, focusing on how the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00427v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00427v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00427v1-abstract-full" style="display: none;">
        In this study, we aim to determine and solve the deficiency of Stable Diffusion Inpainting (SDI) in following the instruction of both prompt and mask. Due to the training bias from masking, the inpainting quality is hindered when the prompt instruction and image condition are not related. Therefore, we conduct a detailed analysis of the internal representations learned by SDI, focusing on how the mask input influences the cross-attention layer. We observe that adapting text key tokens toward the input mask enables the model to selectively paint within the given area. Leveraging these insights, we propose FreeCond, which adjusts only the input mask condition and image condition. By increasing the latent mask value and modifying the frequency of image condition, we align the cross-attention features with the model&#39;s training bias to improve generation quality without additional computation, particularly when user inputs are complicated and deviate from the training setup. Extensive experiments demonstrate that FreeCond can enhance any SDI-based model, e.g., yielding up to a 60% and 58% improvement of SDI and SDXLI in the CLIP score.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00427v1-abstract-full').style.display = 'none'; document.getElementById('2412.00427v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00418">arXiv:2412.00418</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00418">pdf</a>, <a href="https://arxiv.org/format/2412.00418">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Mixture of Experts for Node Classification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+Y">Yu Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yiqi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lang%2C+W">WeiXuan Lang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+J">Jiaxin Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+P">Pan Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+A">Aiping Li</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00418v1-abstract-short" style="display: inline;">
        Nodes in the real-world graphs exhibit diverse patterns in numerous aspects, such as degree and homophily. However, most existent node predictors fail to capture a wide range of node patterns or to make predictions based on distinct node patterns, resulting in unsatisfactory classification performance. In this paper, we reveal that different node predictors are good at handling nodes with specific&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00418v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00418v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00418v1-abstract-full" style="display: none;">
        Nodes in the real-world graphs exhibit diverse patterns in numerous aspects, such as degree and homophily. However, most existent node predictors fail to capture a wide range of node patterns or to make predictions based on distinct node patterns, resulting in unsatisfactory classification performance. In this paper, we reveal that different node predictors are good at handling nodes with specific patterns and only apply one node predictor uniformly could lead to suboptimal result. To mitigate this gap, we propose a mixture of experts framework, MoE-NP, for node classification. Specifically, MoE-NP combines a mixture of node predictors and strategically selects models based on node patterns. Experimental results from a range of real-world datasets demonstrate significant performance improvements from MoE-NP.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00418v1-abstract-full').style.display = 'none'; document.getElementById('2412.00418v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.00403">arXiv:2412.00403</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.00403">pdf</a>, <a href="https://arxiv.org/format/2412.00403">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fine-Tuning Pre-trained Large Time Series Models for Prediction of Wind Turbine SCADA Data
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+Y">Yuwei Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+T">Tao Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+C">Chenlong Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+K">Keyu Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+C">Chao Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+D">Dongxiang Jiang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.00403v1-abstract-short" style="display: inline;">
        The remarkable achievements of large models in the fields of natural language processing (NLP) and computer vision (CV) have sparked interest in their application to time series forecasting within industrial contexts. This paper explores the application of a pre-trained large time series model, Timer, which was initially trained on a wide range of time series data from multiple domains, in the pre&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00403v1-abstract-full').style.display = 'inline'; document.getElementById('2412.00403v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.00403v1-abstract-full" style="display: none;">
        The remarkable achievements of large models in the fields of natural language processing (NLP) and computer vision (CV) have sparked interest in their application to time series forecasting within industrial contexts. This paper explores the application of a pre-trained large time series model, Timer, which was initially trained on a wide range of time series data from multiple domains, in the prediction of Supervisory Control and Data Acquisition (SCADA) data collected from wind turbines. The model was fine-tuned on SCADA datasets sourced from two wind farms, which exhibited differing characteristics, and its accuracy was subsequently evaluated. Additionally, the impact of data volume was studied to evaluate the few-shot ability of the Timer. Finally, an application study on one-turbine fine-tuning for whole-plant prediction was implemented where both few-shot and cross-turbine generalization capacity is required. The results reveal that the pre-trained large model does not consistently outperform other baseline models in terms of prediction accuracy whenever the data is abundant or not, but demonstrates superior performance in the application study. This result underscores the distinctive advantages of the pre-trained large time series model in facilitating swift deployment.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.00403v1-abstract-full').style.display = 'none'; document.getElementById('2412.00403v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

</ol>


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
                                     
          
          <li>
            <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=50"
              class="pagination-link "
              aria-label="Page 2"
              aria-current="page">2
            </a>
          </li>
          
          <li>
            <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=100"
              class="pagination-link "
              aria-label="Page 3"
              aria-current="page">3
            </a>
          </li>
          
          <li>
            <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=150"
              class="pagination-link "
              aria-label="Page 4"
              aria-current="page">4
            </a>
          </li>
          
          <li>
            <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Artificial+Intelligence&amp;terms-0-field=cross_list_category&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=exclude&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2024-06-01&amp;date-to_date=2024-12-01&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=200"
              class="pagination-link "
              aria-label="Page 5"
              aria-current="page">5
            </a>
          </li>
          
          <li><span class="pagination-ellipsis">&hellip;</span></li>
        
      
    </ul>
  </nav>
  

    
  

      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>